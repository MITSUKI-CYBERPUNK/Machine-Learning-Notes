详见[[0 吴恩达机器学习ML]]

## 1.1 组成元素
+ 数据Data
+ 任务Task
+ 性能度量Quality Metric
+ 模型Model
![640.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/640.jpg)

## 1.2 数据Data
+ 数据 (data) 是经验的另一种说法，也是信息的载体。数据可分为 ^9f461b
	1. 结构化数据和非结构化数据 (按数据具体类型划分)
	2. 原始数据和加工数据 (按数据表达形式划分)
	3. 样本内数据和样本外数据 (按数据统计性质划分)

### 1.2.1 结构化与非结构化
+ **结构化数据 (structured data)** 是由**二维表结构**来逻辑表达和实现的数据。非结构化数据是没有预定义的数据，不便用数据库二维表来表现的数据。
+ **非结构化数据**包括图片，文字，语音和视屏，棋谱等。
	+ 应用实例有：
		+ 深度学习卷积神经网络（CNN）人脸识别或物体分类
		+ 深度学习循环神经网络（RNN）对语音数据做语音识别或机器对话，对文字数据做文本生成或阅读理解
		+ 增强学习的AlphaGo

+ 以下术语必须搞清楚:(以LBJ四场比赛数据举例)
![i2xd72yr.bmp](https://aquazone.oss-cn-guangzhou.aliyuncs.com/i2xd72yr.bmp)

-  术语：
	- 每行的记录 (这是一场比赛詹姆斯的个人统计) ，称为一个**示例** (instance)
	- 反映对象在某方面的性质，例如得分，篮板，助攻，称为**特征** (feature) 或**输入** (input)
	- 特征上的取值，例如「示例 1」对应的 27, 10, 12 称为**特征值** (feature value)
	- 关于示例结果的信息，例如赢，称为**标签** (label) 或**输出** (output)
	- 包含标签信息的示例，则称为**样例** (example)，即样例 = (特征, 标签)
	- 从数据中学得模型的过程称为**学习** (learning) 或**训练** (training)
	- 在训练数据中，每个样例称为**训练样例** (training example)，整个集合称为**训练集** (training set)

### 1.2.2 原始和加工
+ 计算机处理数值型的结构型数据最有效率，但是现实世界到处是原始数据，分为两类：
	- 非结构数据比如图片和文字型数据 
	- 结构型数据的分类型变量 
+ 具体例子有：
	+ 图片用RGB像素表示，并排成数值列向量
	+ 将文本用独热编码到包含128个字符的ASCII表
	+ 将分类型变量用二进制编码

### 1.2.3 样本内与样本外
+ 在统计中，把研究对象的全体称为**总体 (population)**，而把组成总体的各个元素称为**个体**，把从总体中抽取的若干个体称为**样本 (sample)**，计算样本里的某个数据作为总体某个数据的推理(Inference)。
+ 在机器学习中，定义却略有不同：
	+ **样本内数据**是用来训练模型的数据，也叫训练数据。它们是已知的，可计算统计的。
	+ **样本外数据**是未来的没见过的新数据。它们是未知的，不可计算统计的。
+ 机器学习在样本内数据训练模型用来预测:-
	+ **样本内预测**：根据训练模型对样本内数据进行预测，可与已知标签比较来评估模型表现
	- **样本外预测**：根据训练模型对样本外数据进行预测，不能与未知的标签比较
- 机器学习的难点就是如何用好的**样本内预测**来保证好的**样本外预测**，我们有[[计算学习理论]]来保证

## 1.3 任务Task
+ 根据学习的任务模式 (训练数据是否有标签)，机器学习可分为四大类：
	1. **有监督学习** (有标签)
	2. **无监督学习** (无标签)
	3. **半监督学习** (有部分标签)
	4. **增强学习** (有评级标签)
    
+ **深度学习**只是一种方法，而不是任务模式，因此与上面四类不属于同一个维度，但是深度学习与它们可以叠加成：深度有监督学习、深度非监督学习、深度半监督学习和深度增强学习。**迁移学习**也是一种方法，也可以分类为有监督迁移学习、非监督迁移学习、半监督迁移学习和增强迁移学习。
+ 机器学习各类之间的关系：![640.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/640.jpg)
 ^c414aa
+ Sklearn里模型主要处理**有监督学习**与**无监督学习**。
+ 通过[[0 吴恩达机器学习ML]]的学习，我们可以知道：
	+ 有监督学习主要任务是分类与回归
	+ 无监督学习主要任务是聚类与降维

## 1.4 性能量度
+ 回归和分类任务中最常见的误差函数以及一些有用的性能度量如下：![640.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/640.png)

+ 回归任务的误差函数估量在数据集 D 上模型的连续型预测值 h(x) 与连续型真实值 y 的距离，h(x) 和 y 可以取任意实数。误差函数是一个非负实值函数，通常使用 E<sub>D</sub>[h] 来表示。图表展示如下:![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240312111444.png)
  ![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240312111519.png)

+ 分类任务的误差函数估量在数据集 D 上模型的离散型预测值 h(x) 与离散型真实值 y 的不一致程度，惯例是 y 和 h(x) 取±1，比如正类取 1 负类取 -1。图表展示如下:![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20240312111642.png)
+ 除上述损失函数之外，分类任务还有很多其他有用的性能度量。

+ **错误率**：分类错误的样本数占样本总数的比例称为错误率 (error rate)，相应的分类正确的样本数占样本总数的比例称为精度 (accuracy)。在 10 个样本中有 2 个样本分类错误，则错误率为 20%，而精度为 80%。
+ **查准率和查全率**：错误率和精度虽然常用，但是不能满足所有任务需求。假定用训练好的模型预测骑士赢球，显然，错误率衡量了多少比赛实际是赢球但预测成输球。但是若我们关心的是“预测出的比赛中有多少是赢球”，或“赢球的比赛中有多少被预测出了”，那么错误率这个单一指标显然就不够用了，这时需要引进更为细分的性能度量，即**查准率 (precision) 和查全率 (recall**)。
+ 其他概念比如混淆矩阵、ROC、AUC 我们再下帖的实例用到时再细讲。

## 1.5 模型
+ 有监督模型：![640.jpg](https://aquazone.oss-cn-guangzhou.aliyuncs.com/640.jpg)
+ 无监督模型包括各种聚类分析 (KMeans, DBSCAN)、主成分分析 (PCA)、独立成分分析 (ICA)、隐含狄利克雷分配 (LDA) 等等。
+ 更多机器学习细节，参考[[0 吴恩达机器学习ML]]


