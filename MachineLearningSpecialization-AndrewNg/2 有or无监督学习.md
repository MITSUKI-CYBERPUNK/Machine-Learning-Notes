# 2 有/无监督学习(Un)Supervised Learning

## 2.1 机器学习定义

> 使计算机无需明确编程即可学习的研究领域。——Arthur Samuel

>  一个程序被认为能从经验**E**中学习，解决任务**T**，达到性能度量值**P**。当且仅当，有了经验**E**后，经过**P**评判，程序在处理T时的性能有所提升。我认为经验**E** 就是程序上万次的自我练习的经验，而任务**T** 就是下棋。性能度量值**P**呢，就是它在与一些新的对手比赛时，赢得比赛的概率。——Tom Mitchell

### 2.1.1 机器学习的类型

+ **监督学习(Supervised learning)**：实际运用使用最多，最先进

+ **无监督学习(Unsupervised learning)**

+ **强化学习(Reinforcement learning)**：应用较少

详细的分类可以参看[[1 机器学习简介#^c414aa]]

## 2.2 监督学习Supervised Learning

### 2.2.1 定义

**给定X Y使得模型学习后可以对给定的任意X得到对应的Y**

与数学的相类似

eg.根据房屋大小预测房价

可用直线或者曲线进行拟合

### 2.2.2 回归Regression——无限多的可能

eg.根据房屋大小预测房价

可用直线或者曲线进行拟合

![image-20240126215234389](https://aquazone.oss-cn-guangzhou.aliyuncs.com/image-20240126215234389.png)

监督学习指的就是我们给学习算法一个数据集。这个数据集由“**正确答案**”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做**回归问题**。

一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。

回归这个词的意思是，**我们在试着推测出这一系列连续值的属性**。

### 2.2.3 分类Classification——有限多的输出

eg.推测乳腺癌良性与否

![image-20240126215640958](https://aquazone.oss-cn-guangzhou.aliyuncs.com/image-20240126215640958.png)

横轴表示肿瘤的大小，纵轴1和0表示是或者不是恶性肿瘤

eg.估算肿瘤是恶性的或是良性的概率。用术语来讲，这是一个**分类问题**。

**分类**指的是，我们试着推测出离散的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。0 代表良性，1 表示第1类乳腺癌，2表示第2类癌症，3表示第3类，但这也是分类问题。

我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本。现在我们不全部画**X**，良性的肿瘤改成用 **O** 表示，恶性的继续用 **X** 表示。来预测肿瘤的恶性与否。

在其它一些机器学习问题中，可能会遇到**不止一种特征**。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，我朋友研究这个问题时，通常采用这些特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。

那种算法不仅能处理2种3种或5种特征，即使有**无限多种特征都可以处理**。

![image-20240126215945605](https://aquazone.oss-cn-guangzhou.aliyuncs.com/image-20240126215945605.png)

找到一根“**边界线**”，来划分不同肿瘤情况

上图中，我列举了总共5种不同的特征，坐标轴上的两种和右边的3种，但是在一些学习问题中，你希望不只用3种或5种特征。相反，你想用**无限多**种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。如何处理无限特征？**我们以后会讲一个算法，叫支持向量机，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。**想象一下，我没有写下这两种和右边的三种特征，而是在一个无限长的列表里面，一直写一直写不停的写，写下无限多个特征，事实上，我们能用算法来处理它们。



### 2.2.4 总结

现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，**我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测**，就像房子和肿瘤的例子中做的那样。我们还介绍了**回归问题，即通过回归来推出一个连续的输出**，之后我们介绍了**分类问题，其目标是推出一组离散的结果。(结果连续与否)**



## 2.3 无监督学习Unsupervised Learning

### 2.3.1 特点与区别

![image-20240127204154443](https://aquazone.oss-cn-guangzhou.aliyuncs.com/image-20240127204154443.png)![image-20240127204217120](https://aquazone.oss-cn-guangzhou.aliyuncs.com/image-20240127204217120.png)

**监督学习:每个示例都与一个输出标签y相关联**，例如良性与恶性

**无监督学习:给定的数据与任何输出标签y无关**（仅输入 不输出），例如给定了有关患者及其肿瘤大小关于患者年龄的数据，不要求良性或者恶性，因此没有得到任何标签。我们的工作是**不试图监督算法，找到一些结构或模式，或者只是在数据中找到一些有趣的东西。**

**No Right Answer**



### 2.3.2 聚类Clustering

将相似的数据点组合在一起

无监督学习算法可能会把这些肿瘤数据分成两个不同的簇（但并不追究肿瘤种类）。所以叫做**聚类算法**。事实证明，它能被用在很多地方。

聚类应用：

+ 谷歌新闻搜索非常多的新闻事件，自动地把它们聚类到一起。这些新闻事件全是**同一主题**的，这就是"**聚**"。而且该算法在没有监督的情况下自行计算出今天的新闻文章有哪些并聚合。
+ 聚类之于基因学：**把个体聚类到不同的类或不同类型的组**。我们没有提前告知算法一些信息（聚类标准和数据里面的什么）因为**我们没有给算法正确答案来回应数据集中的数据**，所以这就是无监督学习。
+ 组织大型计算机集群：分类使机器协同工作
+ 社交网络的分析:划分用户，圈子等
+ 细分市场分类  



### 2.3.3  异常检测Anomaly Detection

**用于检测异常事件**

eg.金融系统的欺诈检测，关注异常事件。 



### 2.3.4 降维 Dimensionality Reduction

**将一个大数据集神奇地压缩成一个小得多的数据集，同时丢失尽可能少的信息。**